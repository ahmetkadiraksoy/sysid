import java.io.BufferedReader;
import java.io.FileNotFoundException;
import java.io.FileReader;
import java.io.IOException;
import java.util.Arrays;

public class GAFitnessCalc {
    // Calculate individuals' fitness by comparing it to our candidate solution
    static double getFitness(GAIndividual individual, GAParameters gaParameters) {
        // check if this gene has already been calculated before
        synchronized (gaParameters) {
            for (int i = 0; i < gaParameters.preCalculatedGenes.size(); i++) {
                if (Arrays.equals(individual.getGeneArray(), gaParameters.preCalculatedGenes.get(i).genes)) {
                    return gaParameters.preCalculatedGenes.get(i).fitness;
                }
            }
        }

        String weight_tokens[] = gaParameters.weights.split(",");

        ////////////////
        // Parameters //
        ////////////////
        BufferedReader reader;
        int no_of_features = individual.size();
        int no_of_features_selected = 0;
        double overall_performance_sum = 0;
        String parameters_to_be_deleted = ""; // concatenated string of features to be removed

        //////////////////////////////////////////////////////////////////////////////
        // Among the selected features, find the ones which contain all null values //
        // (those which appear as string in the arff file) and set them in the 'individual' to 0
        //////////////////////////////////////////////////////////////////////////////
        for (int i = 0; i < individual.size(); i++) { // for each feature
            if (individual.getGene(i) == 1) { // if this feature is not selected to be removed by GA
                no_of_features_selected++;
                int count = 0;
                for (int j = 0; j < gaParameters.no_of_os_instances; j++) { // for each instance
                    boolean feature_is_null = true;
                    // check if this feature is all null (string in arff)
                    try {
                        reader = new BufferedReader(new FileReader(gaParameters.work_folder + "/train_instance_" + (j+1)));

                        String line;
                        while ((line = reader.readLine()) != null) {
                            if (!line.trim().isEmpty()) {
                                String tokens[] = line.split(",");
                                if (!(tokens[i].equals("?"))) {
                                    feature_is_null = false;
                                    break;
                                }
                            }
                        }

                        if (feature_is_null) {
                            count++;
                            break;
                        }
                    } catch (FileNotFoundException e) {
                        e.printStackTrace();
                    } catch (IOException e) {
                        e.printStackTrace();
                    }
                }

                // if all null, then set it to be removed in the 'parameters_to_be_deleted'
                if (count > 0)
                    individual.setGene(i, (byte) 0);
            }
        }

        //////////////////////////////////////////////////////
        // Check if all features are selected to be removed //
        //////////////////////////////////////////////////////
        int no_of_zeros_in_chromosome = 0;
        for (int i = 0; i < no_of_features; i++) // for each feature
            if (individual.getGene(i) == 0)
                no_of_zeros_in_chromosome++;

        // If all features are selected to be removed, return 0's
        if (no_of_zeros_in_chromosome == individual.size())
            return 0;

        // If all features are not selected to be removed
        if (no_of_zeros_in_chromosome > 0) {
            ////////////////////////////////////////////////////////////////////////////////////////////////////////////
            // Find the positions of the features to be removed and set them to the 'parameters_to_be_deleted' string //
            ////////////////////////////////////////////////////////////////////////////////////////////////////////////
            for (int i = 0; i < individual.size(); i++) {
                if (individual.getGene(i) == 0) {
                    parameters_to_be_deleted += (i+1);
                    parameters_to_be_deleted += ",";
                }
            }
            // Remove the last comma generated by the for loop
            parameters_to_be_deleted = parameters_to_be_deleted.substring(0, parameters_to_be_deleted.length()-1); // remove the last comma
        }

        ////////////////
        // TRAIN TEST //
        ////////////////
        for (int test_instance_no = 0; test_instance_no < gaParameters.no_of_os_instances; test_instance_no++) { // for each instance
            double performance_sum = 0;

            // For each test instance
            for (int train_instance_no = 0; train_instance_no < gaParameters.no_of_os_instances; train_instance_no++) {
                if (train_instance_no != test_instance_no) {
                    try {
                        performance_sum += new ClassifyML().train_test(gaParameters.work_folder + "/train_instance_" + (train_instance_no+1) + ".arff", gaParameters.work_folder + "/train_instance_" + (test_instance_no+1) + ".arff", parameters_to_be_deleted, gaParameters.classifier, false, true).get(0);
                    } catch (Exception e) {
                        e.printStackTrace();
                    }
                }
            }

            overall_performance_sum += performance_sum / (gaParameters.no_of_os_instances - 1);
        }

        double result = overall_performance_sum / gaParameters.no_of_os_instances;

        ////////////////////////
        // Return the results //
        ////////////////////////
        double classification_result = result * Double.parseDouble(weight_tokens[0]);
        double feature_result = (((no_of_features - no_of_features_selected) / (double) no_of_features) * 100) * Double.parseDouble(weight_tokens[1]);
        double result_to_return = classification_result + feature_result;

        // add the gene to precalculated set
        synchronized (gaParameters) {
            boolean found = false;
            for (int i = 0; i < gaParameters.preCalculatedGenes.size(); i++) {
                if (Arrays.equals(individual.getGeneArray(), gaParameters.preCalculatedGenes.get(i).genes)) {
                    found = true;
                    break;
                }
            }

            if (!found) {
                PreCalculatedGenes test = new PreCalculatedGenes();
                test.genes = new byte[gaParameters.no_of_features];
                for (int i = 0; i < gaParameters.no_of_features; i++)
                    test.genes[i] = individual.getGeneArray()[i];
                test.fitness = result_to_return;
                gaParameters.preCalculatedGenes.add(test);
            }
        }

        return result_to_return;
    }

//    public static double find_entropies(String filename) {
//        int number_of_attributes = 0;
//        ArrayList<String> examples = new ArrayList<>();
//        BufferedReader br = null;
//
//        try {
//            String sCurrentLine;
//            br = new BufferedReader(new FileReader(filename));
//
//            while ((sCurrentLine = br.readLine()) != null)
//                examples.add(sCurrentLine);
//        } catch (IOException e) {
//            e.printStackTrace();
//        } finally {
//            try {
//                if (br != null)br.close();
//            } catch (IOException ex) {
//                ex.printStackTrace();
//            }
//        }
//
//        number_of_attributes = examples.get(0).split(",").length - 1;
//
//        // Find the number of unique classes
//        ArrayList<String> unique_classes = new ArrayList<>();
//        for (int i = 0; i < examples.size(); i++)
//        {
//            String example_class = examples.get(i).split(",")[number_of_attributes]; // get the class from example j
//            boolean exists = false;
//            for (int j = 0; j < unique_classes.size(); j++)
//            {
//                if (unique_classes.get(j).equals(example_class))
//                {
//                    exists = true;
//                    break;
//                }
//            }
//
//            if (!exists)
//                unique_classes.add(example_class);
//        }
//        int no_of_classes = unique_classes.size();
//
//        //ArrayList<String> entropies = new ArrayList<>(); // holds entropy values for features
//        double average_entropy = 0;
//
//        for (int i = 0; i < number_of_attributes; i++) // for each attribute
//        {
//            ArrayList<test2> instances = new ArrayList<>(); // holds unique instances for each attribute
//            ArrayList<ArrayList<test2>> instance_classes = new ArrayList<>(); // holds unique classes for each attribute
//
//            for (int j = 0; j < examples.size(); j++) // for each example
//            {
//                String example_attribute = examples.get(j).split(",")[i]; // get the attribute value from example j
//                String example_class = examples.get(j).split(",")[number_of_attributes]; // get the class from example j
//
//                // if instance does not exist in list, add it. if exists, increment occurrence
//                boolean instance_exists = false;
//                for (int k = 0; k < instances.size(); k++) // loop through the instances
//                {
//                    if (instances.get(k).text.equals(example_attribute)) // if current instance is found
//                    {
//                        instance_exists = true;
//                        instances.get(k).occurance++; // increment the instance occurance
//
//                        // If the class of the current example exists, increment it
//                        boolean class_exists = false;
//                        for (int l = 0; l < instance_classes.get(k).size(); l++)
//                        {
//                            if (instance_classes.get(k).get(l).text.equals(example_class))
//                            {
//                                class_exists = true;
//                                ArrayList<test2> item = instance_classes.get(k);
//                                item.get(l).occurance++;
//                                instance_classes.set(k, item);
//
//                                break;
//                            }
//                        }
//
//                        // If the class of the current example does not exist, add it
//                        if (!class_exists)
//                        {
//                            ArrayList<test2> item = instance_classes.get(k);
//                            test2 test2 = new test2();
//                            test2.text = example_class;
//                            item.add(test2);
//                            instance_classes.set(k, item);
//                        }
//
//                        break;
//                    }
//                }
//
//                if (!instance_exists)
//                {
//                    test2 test2 = new test2();
//                    test2.text = example_attribute;
//                    instances.add(test2); // add instance
//
//                    // Add class
//                    test2 = new test2();
//                    test2.text = example_class;
//
//                    ArrayList<test2> item = new ArrayList<>();
//                    item.add(test2);
//                    instance_classes.add(item);
//                }
//            }
//
//            double entropy = 0;
//            for (int j = 0; j < instances.size(); j++)
//            {
//                double without_rate = 0;
//                for (int k = 0; k < instance_classes.get(j).size(); k++)
//                {
//                    double term = instance_classes.get(j).get(k).occurance/((double)instances.get(j).occurance);
//                    without_rate = without_rate + ((-1) * term * (Math.log(term)/Math.log(no_of_classes)));
//                }
//                without_rate = without_rate * (instances.get(j).occurance/((double)examples.size()));
//                entropy = entropy + without_rate;
//            }
//            //entropies.add(Double.toString(entropy));
//            average_entropy += entropy;
//        }
//
//        return (1 - average_entropy/number_of_attributes);
//    }

//    public void remove_arff_headers(String input_filename, String output_filename) {
//        try {
//            BufferedReader in = new BufferedReader(new FileReader(input_filename));
//            PrintWriter out = new PrintWriter (output_filename);
//
//            boolean start_writing = false;
//            for (String line; (line = in.readLine()) != null;) {
//                if (line.equals("@data")) {
//                    start_writing = true;
//                    line = in.readLine();
//                }
//
//                if ((start_writing) && (!line.trim().isEmpty()))
//                    out.println(line);
//            }
//
//            in.close();
//            out.close();
//        } catch (FileNotFoundException e) {
//            e.printStackTrace();
//        } catch (IOException e) {
//            e.printStackTrace();
//        };
//    }
}

//class test2 {
//    String text = "";
//    int occurance = 1;
//}
